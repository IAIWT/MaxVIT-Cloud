{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "11.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/10]: 100%|██████████| 1250/1250 [07:21<00:00,  2.83it/s, loss=0.75]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Train Loss: 0.8791, Train Accuracy: 66.75%, Train Precision: 0.65, Train Recall: 0.67, Train F1-Score: 0.66\n",
      "\n",
      "Test Accuracy for maxvit_tiny_tf_224.in1k after epoch 1: 64.07%\n",
      "Test Precision: 0.68, Test Recall: 0.64, Test F1-Score: 0.61\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [2/10]: 100%|██████████| 1250/1250 [06:45<00:00,  3.08it/s, loss=0.372] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Train Loss: 0.6035, Train Accuracy: 77.09%, Train Precision: 0.76, Train Recall: 0.77, Train F1-Score: 0.77\n",
      "\n",
      "Test Accuracy for maxvit_tiny_tf_224.in1k after epoch 2: 64.63%\n",
      "Test Precision: 0.67, Test Recall: 0.65, Test F1-Score: 0.64\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [3/10]: 100%|██████████| 1250/1250 [06:45<00:00,  3.08it/s, loss=0.147] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Train Loss: 0.5134, Train Accuracy: 80.40%, Train Precision: 0.80, Train Recall: 0.80, Train F1-Score: 0.80\n",
      "\n",
      "Test Accuracy for maxvit_tiny_tf_224.in1k after epoch 3: 66.52%\n",
      "Test Precision: 0.68, Test Recall: 0.67, Test F1-Score: 0.64\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [4/10]: 100%|██████████| 1250/1250 [06:45<00:00,  3.08it/s, loss=0.654] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Train Loss: 0.4736, Train Accuracy: 81.69%, Train Precision: 0.81, Train Recall: 0.82, Train F1-Score: 0.81\n",
      "\n",
      "Test Accuracy for maxvit_tiny_tf_224.in1k after epoch 4: 69.82%\n",
      "Test Precision: 0.75, Test Recall: 0.70, Test F1-Score: 0.68\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [5/10]: 100%|██████████| 1250/1250 [06:45<00:00,  3.08it/s, loss=0.301] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Train Loss: 0.4258, Train Accuracy: 83.43%, Train Precision: 0.83, Train Recall: 0.83, Train F1-Score: 0.83\n",
      "\n",
      "Test Accuracy for maxvit_tiny_tf_224.in1k after epoch 5: 72.19%\n",
      "Test Precision: 0.74, Test Recall: 0.72, Test F1-Score: 0.71\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [6/10]:  84%|████████▍ | 1048/1250 [05:39<01:05,  3.09it/s, loss=0.295] "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import timm\n",
    "import torch\n",
    "import zipfile, os\n",
    "import csv\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Check CUDA availability\n",
    "print(torch.cuda.is_available())  # Should return True\n",
    "print(torch.version.cuda)         # Should match the installed CUDA version\n",
    "\n",
    "local_zip = os.path.join(os.getcwd(), 'GCD.zip')\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall(os.getcwd())\n",
    "zip_ref.close()\n",
    "\n",
    "train_dir = os.path.join(os.getcwd(), 'GCD', 'train')\n",
    "test_dir = os.path.join(os.getcwd(), 'GCD', 'test')\n",
    "\n",
    "# Transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images to 224x224\n",
    "    transforms.ToTensor(),           # Convert images to PyTorch tensors\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize\n",
    "])\n",
    "\n",
    "# Custom dataset class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        self.class_names = os.listdir(data_dir)\n",
    "\n",
    "        for label, class_name in enumerate(self.class_names):\n",
    "            class_dir = os.path.join(data_dir, class_name)\n",
    "            for img_name in os.listdir(class_dir):\n",
    "                img_path = os.path.join(class_dir, img_name)\n",
    "                self.images.append(img_path)\n",
    "                self.labels.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.images[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# Data loaders\n",
    "train_dataset = CustomDataset(data_dir=train_dir, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "test_dataset = ImageFolder(root=test_dir, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Function for training and evaluation\n",
    "def train_and_evaluate_model(model_name, model, train_loader, test_loader, num_epochs=10):\n",
    "    model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Create a directory to save results and models\n",
    "    results_dir = \"results\"\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "    log_file_path = os.path.join(results_dir, f\"{model_name}_log.txt\")\n",
    "    model_save_path = os.path.join(results_dir, f\"{model_name}.pth\")\n",
    "    csv_file_path = os.path.join(results_dir, f\"{model_name}_results.csv\")\n",
    "\n",
    "    # Initialize CSV file\n",
    "    with open(csv_file_path, \"w\", newline=\"\") as csv_file:\n",
    "        csv_writer = csv.writer(csv_file)\n",
    "        csv_writer.writerow([\"Epoch\", \"Train Loss\", \"Train Accuracy\", \"Train Precision\", \"Train Recall\", \"Train F1-Score\", \"Test Accuracy\", \"Test Precision\", \"Test Recall\", \"Test F1-Score\"])\n",
    "\n",
    "    with open(log_file_path, \"w\") as log_file:\n",
    "        log_file.write(f\"Training model: {model_name}\\n\")\n",
    "\n",
    "        # Training loop\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()  # Set the model to training mode\n",
    "            epoch_loss = 0  # To accumulate loss for the epoch\n",
    "            correct_predictions = 0\n",
    "            total_samples = 0\n",
    "            all_targets = []\n",
    "            all_preds = []\n",
    "\n",
    "            progress_bar = tqdm(train_loader, desc=f\"Epoch [{epoch+1}/{num_epochs}]\")  # Progress bar\n",
    "\n",
    "            for inputs, targets in progress_bar:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)  # Move to device\n",
    "\n",
    "                optimizer.zero_grad()  # Zero the gradients\n",
    "                outputs = model(inputs)  # Forward pass\n",
    "                loss = criterion(outputs, targets)  # Compute loss\n",
    "                loss.backward()  # Backward pass\n",
    "                optimizer.step()  # Update weights\n",
    "\n",
    "                # Update progress bar description with the current loss\n",
    "                epoch_loss += loss.item()\n",
    "                progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "                # Calculate accuracy\n",
    "                _, preds = torch.max(outputs, dim=1)\n",
    "                correct_predictions += (preds == targets).sum().item()\n",
    "                total_samples += targets.size(0)\n",
    "                all_targets.extend(targets.tolist())\n",
    "                all_preds.extend(preds.tolist())\n",
    "\n",
    "            avg_loss = epoch_loss / len(train_loader)\n",
    "            accuracy = correct_predictions / total_samples * 100\n",
    "\n",
    "            # Calculate precision, recall, and F1-score for the train set\n",
    "            precision, recall, f1, _ = precision_recall_fscore_support(all_targets, all_preds, average='weighted')\n",
    "\n",
    "            # Log training metrics\n",
    "            train_metrics = (f\"Epoch [{epoch+1}/{num_epochs}], \"\n",
    "                             f\"Train Loss: {avg_loss:.4f}, \"\n",
    "                             f\"Train Accuracy: {accuracy:.2f}%, \"\n",
    "                             f\"Train Precision: {precision:.2f}, \"\n",
    "                             f\"Train Recall: {recall:.2f}, \"\n",
    "                             f\"Train F1-Score: {f1:.2f}\\n\")\n",
    "            print(train_metrics)\n",
    "            log_file.write(train_metrics)\n",
    "\n",
    "            # Evaluate the model on the test set after each epoch\n",
    "            model.eval()  # Set model to evaluation mode\n",
    "            correct_predictions = 0\n",
    "            total_samples = 0\n",
    "            all_targets = []\n",
    "            all_preds = []\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for inputs, targets in test_loader:\n",
    "                    inputs, targets = inputs.to(device), targets.to(device)\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, dim=1)\n",
    "                    correct_predictions += (preds == targets).sum().item()\n",
    "                    total_samples += targets.size(0)\n",
    "                    all_targets.extend(targets.tolist())\n",
    "                    all_preds.extend(preds.tolist())\n",
    "\n",
    "            test_accuracy = correct_predictions / total_samples * 100\n",
    "\n",
    "            # Calculate precision, recall, and F1-score for the test set\n",
    "            precision, recall, f1, _ = precision_recall_fscore_support(all_targets, all_preds, average='weighted')\n",
    "\n",
    "            # Log test metrics\n",
    "            test_metrics = (f\"Test Accuracy for {model_name} after epoch {epoch+1}: {test_accuracy:.2f}%\\n\"\n",
    "                            f\"Test Precision: {precision:.2f}, Test Recall: {recall:.2f}, Test F1-Score: {f1:.2f}\\n\\n\")\n",
    "            print(test_metrics)\n",
    "            log_file.write(test_metrics)\n",
    "\n",
    "            # Write metrics to CSV\n",
    "            with open(csv_file_path, \"a\", newline=\"\") as csv_file:\n",
    "                csv_writer = csv.writer(csv_file)\n",
    "                csv_writer.writerow([epoch+1, avg_loss, accuracy, precision, recall, f1, test_accuracy, precision, recall, f1])\n",
    "\n",
    "        # Save the trained model\n",
    "        torch.save(model.state_dict(), model_save_path)\n",
    "\n",
    "# Models to train\n",
    "models = [\n",
    "    ('maxvit_tiny_tf_224.in1k', timm.create_model('maxvit_tiny_tf_224.in1k', pretrained=True, num_classes=7)),\n",
    "    ('maxvit_tiny_rw_224.sw_in1k', timm.create_model('maxvit_tiny_rw_224.sw_in1k', pretrained=True, num_classes=7)),\n",
    "    ('maxvit_small_tf_224.in1k', timm.create_model('maxvit_small_tf_224.in1k', pretrained=True, num_classes=7))\n",
    "]\n",
    "\n",
    "# Train and evaluate each model\n",
    "for model_name, model in models:\n",
    "    train_and_evaluate_model(model_name, model, train_loader, test_loader, num_epochs=10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ultralytics_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
