{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\ultralytics_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "import timm\n",
    "import torch\n",
    "import zipfile,os\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm  # Import tqdm for progress bar\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\In AI We Trust\\\\GCD.zip'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(os.getcwd(), 'GCD.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_zip = os.path.join(os.getcwd(), 'GCD.zip')\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall(os.getcwd())\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\In AI We Trust\\GCD\\test\n"
     ]
    }
   ],
   "source": [
    "#train_dir = os.path.join(os.getcwd(), 'GCD', 'train')\n",
    "test_dir = os.path.join(os.getcwd(), 'GCD', 'test')\n",
    "\n",
    "print(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "11.8\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())  # Should return True\n",
    "print(torch.version.cuda)         # Should match the installed CUDA version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = timm.create_model(\n",
    "    'maxvit_small_tf_224.in1k',\n",
    "    pretrained=True,\n",
    "    num_classes=7,\n",
    ")\n",
    "model = model.eval()\n",
    "\n",
    "# get model specific transforms (normalization, resize)\n",
    "data_config = timm.data.resolve_model_data_config(model)\n",
    "transforms = timm.data.create_transform(**data_config, is_training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntrain_dir = Path(train_dir)\\n\\nfor img_path in train_dir.rglob(\"*.*\"):  # Recursively find all files\\n    if img_path.suffix.lower() in [\".jpg\", \".jpeg\", \".png\"]:  # Check for valid image extensions\\n        img = Image.open(img_path).convert(\"RGB\")  # Open the image and convert to RGB\\n        img_tensor = transforms(img).unsqueeze(0)  # Preprocess and add batch dimension\\n\\n        # Pass the image through the model\\n        output = model.forward_features(transforms(img_tensor))\\n\\n        print(f\"Processed {img_path}: Output Shape - {output[-1].shape if isinstance(output, list) else output.shape}\")\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "train_dir = Path(train_dir)\n",
    "\n",
    "for img_path in train_dir.rglob(\"*.*\"):  # Recursively find all files\n",
    "    if img_path.suffix.lower() in [\".jpg\", \".jpeg\", \".png\"]:  # Check for valid image extensions\n",
    "        img = Image.open(img_path).convert(\"RGB\")  # Open the image and convert to RGB\n",
    "        img_tensor = transforms(img).unsqueeze(0)  # Preprocess and add batch dimension\n",
    "\n",
    "        # Pass the image through the model\n",
    "        output = model.forward_features(transforms(img_tensor))\n",
    "\n",
    "        print(f\"Processed {img_path}: Output Shape - {output[-1].shape if isinstance(output, list) else output.shape}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for data in train_loader:\n",
    "#     print(data)  # This will show you the structure of the data being returned\n",
    "#     inputs, targets = data  # Unpack only if it has the correct structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        self.class_names = os.listdir(data_dir)\n",
    "\n",
    "        for label, class_name in enumerate(self.class_names):\n",
    "            class_dir = os.path.join(data_dir, class_name)\n",
    "            for img_name in os.listdir(class_dir):\n",
    "                img_path = os.path.join(class_dir, img_name)\n",
    "                self.images.append(img_path)\n",
    "                self.labels.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.images[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label  # Ensure this returns a tuple of (image, label)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images to 224x224\n",
    "    transforms.ToTensor(),           # Convert images to PyTorch tensors\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize\n",
    "])\n",
    "\n",
    "# Create an instance of the CustomDataset\n",
    "dataset = CustomDataset(data_dir=test_dir, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(dataset, batch_size=8, shuffle=True)\n",
    "for data in train_loader:\n",
    "    print(data[0].shape)  # This will show you the structure of the data being returned\n",
    "    inputs, targets = data  # Unpack only if it has the correct structure\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/2]: 100%|██████████| 1125/1125 [33:16<00:00,  1.77s/it, loss=1.03] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Avg Loss: 1.0363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [2/2]: 100%|██████████| 1125/1125 [33:29<00:00,  1.79s/it, loss=0.259]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/2], Avg Loss: 0.7303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cuda\")\n",
    "model.to(device)\n",
    "num_epochs = 2\n",
    "\n",
    "# Training loop\n",
    "model.train()  # Set the model to training mode\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0  # To accumulate loss for the epoch\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch [{epoch+1}/{num_epochs}]\")  # Progress bar\n",
    "    \n",
    "    for inputs, targets in progress_bar:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)  # Move to device\n",
    "\n",
    "        optimizer.zero_grad()  # Zero the gradients\n",
    "        outputs = model(inputs)  # Forward pass\n",
    "        loss = criterion(outputs, targets)  # Compute loss\n",
    "        loss.backward()  # Backward pass\n",
    "        optimizer.step()  # Update weights\n",
    "\n",
    "        # Update progress bar description with the current loss\n",
    "        epoch_loss += loss.item()\n",
    "        progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "    avg_loss = epoch_loss / len(train_loader)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Avg Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "test_dataset = ImageFolder(root=test_dir, transform=transforms)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# 4. Define testing loop\n",
    "correct_predictions = 0\n",
    "total_samples = 0\n",
    "all_targets = []\n",
    "all_preds = []\n",
    "\n",
    "'''\n",
    "with torch.no_grad():  # Disable gradient computation for inference\n",
    "    for inputs, targets in test_loader:\n",
    "        # Perform forward pass\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Get predicted class indices\n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "\n",
    "        # Compare predictions with ground truth\n",
    "        correct_predictions += (preds == targets).sum().item()\n",
    "        total_samples += targets.size(0)\n",
    "\n",
    "        # Store predictions and labels for metrics\n",
    "        all_targets.extend(targets.tolist())\n",
    "        all_preds.extend(preds.tolist())\n",
    "'''\n",
    "# Perform forward pass\n",
    "outputs = model(inputs)\n",
    "\n",
    "# Get predicted class indices\n",
    "_, preds = torch.max(outputs, dim=1)\n",
    "\n",
    "# Compare predictions with ground truth\n",
    "correct_predictions += (preds == targets).sum().item()\n",
    "total_samples += targets.size(0)\n",
    "\n",
    "# Store predictions and labels for metrics\n",
    "all_targets.extend(targets.tolist())\n",
    "all_preds.extend(preds.tolist())\n",
    "\n",
    "accuracy = accuracy_score(all_targets, all_preds)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 3, 224, 224])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/2]: 100%|██████████| 1125/1125 [1:30:39<00:00,  4.83s/it, loss=0.677]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Avg Loss: 1.0315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [2/2]: 100%|██████████| 1125/1125 [1:31:33<00:00,  4.88s/it, loss=0.702]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/2], Avg Loss: 0.7358\n",
      "maxvit_small_tf_224.in1k\n",
      "Accuracy: 87.50%\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "TextIOWrapper.write() takes exactly one argument (3 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 145\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m--> 145\u001b[0m     \u001b[43mfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maccuracy score of \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m : \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    146\u001b[0m     file\u001b[38;5;241m.\u001b[39mwrite(accuracy, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: TextIOWrapper.write() takes exactly one argument (3 given)"
     ]
    }
   ],
   "source": [
    "modelName = ['maxvit_small_tf_224.in1k', 'maxvit_rmlp_base_rw_224.sw_in12k_ft_in1k', 'maxvit_large_tf_224.in1k']\n",
    "\n",
    "for x in modelName:\n",
    "    # choose model\n",
    "    model = timm.create_model(\n",
    "        x,\n",
    "        pretrained=True,\n",
    "        num_classes=7,\n",
    "    )\n",
    "    model = model.eval()\n",
    "\n",
    "    # get model specific transforms (normalization, resize)\n",
    "    data_config = timm.data.resolve_model_data_config(model)\n",
    "    transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "\n",
    "\n",
    "\n",
    "    from torchvision import transforms\n",
    "\n",
    "    class CustomDataset(Dataset):\n",
    "        def __init__(self, data_dir, transform=None):\n",
    "            self.data_dir = data_dir\n",
    "            self.transform = transform\n",
    "            self.images = []\n",
    "            self.labels = []\n",
    "            self.class_names = os.listdir(data_dir)\n",
    "\n",
    "            for label, class_name in enumerate(self.class_names):\n",
    "                class_dir = os.path.join(data_dir, class_name)\n",
    "                for img_name in os.listdir(class_dir):\n",
    "                    img_path = os.path.join(class_dir, img_name)\n",
    "                    self.images.append(img_path)\n",
    "                    self.labels.append(label)\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.images)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            img_path = self.images[idx]\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "            label = self.labels[idx]\n",
    "\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "\n",
    "            return image, label  # Ensure this returns a tuple of (image, label)\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),  # Resize images to 224x224\n",
    "        transforms.ToTensor(),           # Convert images to PyTorch tensors\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize\n",
    "    ])\n",
    "\n",
    "    # Create an instance of the CustomDataset\n",
    "    dataset = CustomDataset(data_dir=test_dir, transform=transform)\n",
    "\n",
    "    train_loader = DataLoader(dataset, batch_size=8, shuffle=True)\n",
    "    for data in train_loader:\n",
    "        print(data[0].shape)  # This will show you the structure of the data being returned\n",
    "        inputs, targets = data  # Unpack only if it has the correct structure\n",
    "        break\n",
    "\n",
    "\n",
    "\n",
    "    # Define loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    #device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    device = torch.device(\"cuda\")\n",
    "    model.to(device)\n",
    "    num_epochs = 2\n",
    "\n",
    "    # Training loop\n",
    "    model.train()  # Set the model to training mode\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0  # To accumulate loss for the epoch\n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch [{epoch+1}/{num_epochs}]\")  # Progress bar\n",
    "        \n",
    "        for inputs, targets in progress_bar:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)  # Move to device\n",
    "\n",
    "            optimizer.zero_grad()  # Zero the gradients\n",
    "            outputs = model(inputs)  # Forward pass\n",
    "            loss = criterion(outputs, targets)  # Compute loss\n",
    "            loss.backward()  # Backward pass\n",
    "            optimizer.step()  # Update weights\n",
    "\n",
    "            # Update progress bar description with the current loss\n",
    "            epoch_loss += loss.item()\n",
    "            progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "        avg_loss = epoch_loss / len(train_loader)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Avg Loss: {avg_loss:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "    test_dataset = ImageFolder(root=test_dir, transform=transforms)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    # 4. Define testing loop\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    all_targets = []\n",
    "    all_preds = []\n",
    "\n",
    "    '''\n",
    "    with torch.no_grad():  # Disable gradient computation for inference\n",
    "        for inputs, targets in test_loader:\n",
    "            # Perform forward pass\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # Get predicted class indices\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "\n",
    "            # Compare predictions with ground truth\n",
    "            correct_predictions += (preds == targets).sum().item()\n",
    "            total_samples += targets.size(0)\n",
    "\n",
    "            # Store predictions and labels for metrics\n",
    "            all_targets.extend(targets.tolist())\n",
    "            all_preds.extend(preds.tolist())\n",
    "    '''\n",
    "    # Perform forward pass\n",
    "    outputs = model(inputs)\n",
    "\n",
    "    # Get predicted class indices\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "\n",
    "    # Compare predictions with ground truth\n",
    "    correct_predictions += (preds == targets).sum().item()\n",
    "    total_samples += targets.size(0)\n",
    "\n",
    "    # Store predictions and labels for metrics\n",
    "    all_targets.extend(targets.tolist())\n",
    "    all_preds.extend(preds.tolist())\n",
    "\n",
    "    # Print accuracy\n",
    "    accuracy = accuracy_score(all_targets, all_preds)\n",
    "    print(x)\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "    import os\n",
    "    with open(\"accuracy.txt\", \"a\") as file:\n",
    "        file.write(\"accuracy score of \", x, \" : \")\n",
    "        file.write(accuracy, \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ultralytics_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
